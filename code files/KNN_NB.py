# -*- coding: utf-8 -*-
"""IR_project_KNN_NB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LMao4jBcouYER_-f8hgRZvDPr9jW2_6w

### Loading Libraries
"""

import pandas as pd
from nltk.stem import PorterStemmer 
ps = PorterStemmer()
from tqdm import tqdm

import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))

"""### Loading data"""

data_path = '/content/drive/My Drive/Colab Notebooks/IR project/facts_opinions.csv'

data = pd.read_csv(data_path)
data.head()

label ={0 : 'Opinion', 1 : 'Facts'}
label

def preprocess(text):

    symbols = list(',.!@#$%^&*()')
    mod_words = []
    words = text.split()
    for word in words :
        word = word.lower()
        for sym in symbols:
            if sym in word:
                word = word.replace(sym, '')
        if word not in stop_words and word.isalpha() :
            word = ps.stem(word)
            if len(word) > 2:
                mod_words.append(word)

    text = ' '.join(mod_words)
    return text

total_data['Text'] = data['Text'].apply(preprocess) # pre processing of data
total_data = data.sample(frac=1).reset_index(drop=True) #shuffling the data
data.head()

"""### Train Test Split"""

Xtrain, Xtest, ytrain, ytest = train_test_split(data['Text'], data['Label'], test_size=0.3, random_state=42)

Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size = 0.2, random_state = 40)

"""### BOW Embeddings"""

from sklearn.feature_extraction.text import CountVectorizer

vec = CountVectorizer(analyzer='word',max_features = 5000,stop_words = 'english')
Xtrain_bow= vec.fit_transform(Xtrain)
Xtrain_bow = Xtrain_bow.toarray()

Xval_bow = vec.transform(Xval).toarray()

Xtest_bow = vec.transform(Xtest)
Xtest_bow = Xtest_bow.toarray()

print('Training data :',Xtrain_bow.shape)
print('Validation data : ', Xval_bow.shape)
print('Testing data :',Xtest_bow.shape)

"""### Fitting KNN on BOW Embeddings"""

num_neighbours = [1,2,3,5,7,9]
accuracy = []
f_scores = []
precisions = []
recall = []
for k in num_neighbours:

    classifier = KNeighborsClassifier(n_neighbors=k)
    classifier.fit(Xtrain_bow, ytrain)
    ypred = classifier.predict(Xval_bow) # validation data
    acc = accuracy_score(yval, ypred)
    f_score = f1_score(yval, ypred, average='macro')
    prec = precision_score(yval, ypred, average='macro')
    rec = recall_score(yval, ypred, average='macro')
    accuracy.append(acc)
    f_scores.append(f_score)
    precisions.append(prec)
    recall.append(rec)

    print(f'K : {k} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

plt.plot(accuracy,label = 'Accuracy')
plt.plot(f_scores,label = 'F-scores')
plt.plot(precisions,label = 'Precisions')
plt.plot(recall,label = 'Recall')
y_pos = np.arange(len(num_neighbours))
plt.xticks(y_pos,num_neighbours)
plt.xlabel('Value of K')
plt.legend()
plt.title('K nearest Neighbors on Validation Data (BOW Approach)')
# plt.savefig('bow_Accuracy.png')
plt.show()

"""### Best KNN for Val test is at Neighbors = 2"""

best_knn_clf = KNeighborsClassifier(n_neighbors=2)
best_knn_clf.fit(Xtrain_bow, ytrain)

ypred = best_knn_clf.predict(Xtest_bow) # Predicting Test data

acc = accuracy_score(ytest, ypred)
f_score = f1_score(ytest, ypred, average='macro')
prec = precision_score(ytest, ypred, average='macro')
rec = recall_score(ytest, ypred, average='macro')


print(f'K : {2} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

"""### TFIDF Word Embeddings"""

vectorizer = TfidfVectorizer(min_df = 0.01,max_features = 10000)

Xtrain_tfidf = vectorizer.fit_transform(Xtrain).todense()
Xval_tfidf = vectorizer.transform(Xval).todense()
Xtest_tfidf = vectorizer.transform(Xtest).todense()


print('Training data :',Xtrain_tfidf.shape)
print('Validation data :',Xval_tfidf.shape)
print('Testing data :',Xtest_tfidf.shape)

"""### Fitting KNN on TFIDF Embeddings"""

num_neighbours = [1,2,3,5,7,9]
accuracy_tfidf_knn = []
f_scores_tfidf_knn = []
precisions_tfidf_knn = []
recall_tfidf_knn = []
for k in num_neighbours:

    classifier = KNeighborsClassifier(n_neighbors=k)
    classifier.fit(Xtrain_tfidf, ytrain)
    ypred = classifier.predict(Xval_tfidf) # validation data
    acc = accuracy_score(yval, ypred)
    f_score = f1_score(yval, ypred, average='macro')
    prec = precision_score(yval, ypred, average='macro')
    rec = recall_score(yval, ypred, average='macro')
    
    accuracy_tfidf_knn.append(acc)
    f_scores_tfidf_knn.append(f_score)
    precisions_tfidf_knn.append(prec)
    recall_tfidf_knn.append(rec)

    print(f'K : {k} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

plt.plot(accuracy_tfidf_knn,label = 'Accuracy')
plt.plot(f_scores_tfidf_knn,label = 'F-scores')
plt.plot(precisions_tfidf_knn,label = 'Precisions')
plt.plot(recall_tfidf_knn,label = 'Recall')
y_pos = np.arange(len(num_neighbours))
plt.xticks(y_pos,num_neighbours)
plt.xlabel('Value of K')
plt.legend()
plt.title('K nearest Neighbors on Validation Data (TFIDF Approach)')
# plt.savefig('bow_Accuracy.png')
plt.show()

"""### Best KNN on Validation data is at k =1|"""

best_knn_tfidf = KNeighborsClassifier(n_neighbors=1)
best_knn_tfidf.fit(Xtrain_tfidf, ytrain)

ypred = best_knn_tfidf.predict(Xtest_tfidf) # Predicting Test data

acc = accuracy_score(ytest, ypred)
f_score = f1_score(ytest, ypred, average='macro')
prec = precision_score(ytest, ypred, average='macro')
rec = recall_score(ytest, ypred, average='macro')


print(f'K : {1} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

"""### Naive Bayes on BOW Embeddings"""

Xtrain_nb, Xtest_nb, ytrain_nb, ytest_nb = train_test_split(data['Text'],data['Label'], test_size=0.3, random_state=42)

Xtrain_nb, Xval_nb, ytrain_nb, yval_nb = train_test_split(Xtrain_nb, ytrain_nb, test_size = 0.2, random_state = 40)

print('Training data Size :',len(Xtrain_nb))
print('Validation data Size :',len(Xval_nb))
print('Test data Size :',len(Xtest_nb))

vec = CountVectorizer(analyzer='word',max_features = 50,stop_words = 'english')
Xtrain_nb_bow= vec.fit_transform(Xtrain_nb).toarray()

Xval_nb_bow = vec.transform(Xval_nb).toarray()

Xtest_nb_bow = vec.transform(Xtest_nb).toarray()


print('Training data :',Xtrain_nb_bow.shape)
print('Validation data : ', Xval_nb_bow.shape)
print('Testing data :',Xtest_nb_bow.shape)

from sklearn.naive_bayes import GaussianNB

alpha_val = [0.01,0.1,1,10, 100,1000]
# var = [1e-9,1e-8,1e-5,1e-2,0.1,1,10,100]
accuracy_bow_nb = []
f_scores_bow_nb = []
precisions_bow_nb = []
recall_bow_nb = []
for a in var:

    clf = MultinomialNB(alpha = a)
    # clf = GaussianNB(var_smoothing = a)
    clf.fit(Xtrain_nb_bow, ytrain_nb)
    ypred = clf.predict(Xval_nb_bow) # validation data
    acc = accuracy_score(yval_nb, ypred)
    f_score = f1_score(yval_nb, ypred, average='macro')
    prec = precision_score(yval_nb, ypred, average='macro')
    rec = recall_score(yval_nb, ypred, average='macro')
    
    accuracy_bow_nb.append(acc)
    f_scores_bow_nb.append(f_score)
    precisions_bow_nb.append(prec)
    recall_bow_nb.append(rec)

    print(f'alpha : {a} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

plt.plot(accuracy_bow_nb,label = 'Accuracy')
plt.plot(f_scores_bow_nb,label = 'F-scores')
plt.plot(precisions_bow_nb,label = 'Precisions')
plt.plot(recall_bow_nb,label = 'Recall')
y_pos = np.arange(len(alpha_val))
plt.xticks(y_pos,alpha_val)
plt.xlabel('Value of Alpha')
plt.legend()
plt.title('Naive bayes on Validation Data (BOW Approach)')
# plt.savefig('bow_Accuracy.png')
plt.show()

best_clf_nb = MultinomialNB(alpha = 1)
best_clf_nb.fit(Xtrain_nb_bow, ytrain_nb)
ypred = best_clf_nb.predict(Xtest_nb_bow) # test data

acc = accuracy_score(ytest_nb, ypred)
f_score = f1_score(ytest_nb, ypred, average='macro')
prec = precision_score(ytest_nb, ypred, average='macro')
rec = recall_score(ytest_nb, ypred, average='macro')


print(f'alpha : {1} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

"""### Naive Bayes TFIDF"""

vectorizer = TfidfVectorizer(min_df = 0.01,max_features = 50)

Xtrain_tfidf = vectorizer.fit_transform(Xtrain).todense()
Xval_tfidf = vectorizer.transform(Xval).todense()
Xtest_tfidf = vectorizer.transform(Xtest).todense()


print('Training data :',Xtrain_tfidf.shape)
print('Validation data :',Xval_tfidf.shape)
print('Testing data :',Xtest_tfidf.shape)

alpha_val = [0.01,0.1,1,10, 100,1000]
accuracy_nb_tfidf = []
f_scores_nb_tfidf = []
precisions_nb_tfidf = []
recall_nb_tfidf = []
for a in alpha_val:

    clf = MultinomialNB(alpha = a)
    clf.fit(Xtrain_tfidf, ytrain)
    ypred = clf.predict(Xval_tfidf) # validation data
    acc = accuracy_score(yval, ypred)
    f_score = f1_score(yval, ypred, average='macro')
    prec = precision_score(yval, ypred, average='macro')
    rec = recall_score(yval, ypred, average='macro')
    
    accuracy_nb_tfidf.append(acc)
    f_scores_nb_tfidf.append(f_score)
    precisions_nb_tfidf.append(prec)
    recall_nb_tfidf.append(rec)

    print(f'alpha : {a} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

plt.plot(accuracy_nb_tfidf,label = 'Accuracy')
plt.plot(f_scores_nb_tfidf,label = 'F-scores')
plt.plot(precisions_nb_tfidf,label = 'Precisions')
plt.plot(recall_nb_tfidf,label = 'Recall')
y_pos = np.arange(len(alpha_val))
plt.xticks(y_pos,alpha_val)
plt.xlabel('Value of Alpha')
plt.legend()
plt.title('Naive bayes on Validation Data (TFIDF Approach)')
# plt.savefig('bow_Accuracy.png')
plt.show()

"""### MNB on Test Data"""

best_clf_nb = MultinomialNB(alpha = 1)
best_clf_nb.fit(Xtrain_tfidf, ytrain_nb)
ypred = best_clf_nb.predict(Xtest_tfidf) # test data

acc = accuracy_score(ytest_nb, ypred)
f_score = f1_score(ytest_nb, ypred, average='macro')
prec = precision_score(ytest_nb, ypred, average='macro')
rec = recall_score(ytest_nb, ypred, average='macro')


print(f'alpha : {1} Accuracy : {acc} Precision : {prec} Recall : {rec} F score : {f_score}')

